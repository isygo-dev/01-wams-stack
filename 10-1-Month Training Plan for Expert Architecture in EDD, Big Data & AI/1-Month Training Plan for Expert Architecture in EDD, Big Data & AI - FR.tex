\documentclass[11pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{fancyhdr}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage[bottom]{footmisc}
\usepackage{times}

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,
    urlcolor=cyan,
    pdftitle={Formation Expert d'1 Mois en Architecture},
    bookmarks=true,
}

\pagestyle{fancy}
\fancyhf{}
\rhead{Formation Expert d'1 Mois en Architecture}
\lhead{ISYGO Consulting Services}
\cfoot{\small Inspire le Succès, Vos Objectifs \& Opportunités}
\rfoot{Page \thepage}

\begin{document}

% Page de couverture
\begin{titlepage}
    \centering
    \vspace*{1cm}
    % Placeholder pour logo (décommentez et remplacez par le fichier logo réel)
    % \includegraphics[width=0.3\textwidth]{isygologo.png}
    \vspace{0.5cm}
    {\color{blue}\hrule height 2pt}
    \vspace{0.5cm}
    {\LARGE \textbf{Formation Expert d'1 Mois en Architecture}\par}
    \vspace{0.3cm}
    {\large \textit{Architecture Pilotée par les Événements, Persistance Polyglotte, Big Data, IA, et Multi-Tenancy}\par}
    \vspace{1.5cm}
    \begin{tabular}{c}
        \large \textbf{Préparé par : Sami Mbarki} \\
        \large Architecte de Solutions, Expert Java \\
        \large ISYGO Consulting Services \\
    \end{tabular}
    \vspace{1cm}
    {\large 17 Septembre 2025 \par}
    \vfill
    \begin{minipage}{0.8\textwidth}
        \centering
        \small \textbf{ISYGO Consulting Services} \\
        \small \textit{Inspire le Succès, Vos Objectifs \& Opportunités} \\
        \small Délivrer une Formation Architecturale Avancée pour les Solutions d'Entreprise \\
        \vspace{0.5cm}
        \small ID du Document : ede2b784-641c-41b2-8f8d-d9307e59fe85 \\
        \small Version : 1.0 \\
        \small Confidentiel : Pour Usage Interne de Formation Uniquement
    \end{minipage}
    {\color{blue}\hrule height 2pt}
\end{titlepage}

\pagestyle{fancy}
\title{Formation Expert d'1 Mois en Microservices et Persistance Polyglotte}
\author{Sami Mbarki \\ Architecte de Solutions, Expert Java \\ ISYGO Consulting Services}
\date{17 Septembre 2025}
\maketitle

% Résumé exécutif
\section*{Résumé Exécutif}
Ce programme intensif d'un mois équipe les professionnels du logiciel expérimentés à concevoir des systèmes de microservices évolutifs, multi-tenants et pilotés par les événements avec persistance polyglotte pour le traitement de documents. Les participants construiront un projet capstone — une Plateforme Intelligente de Traitement de Documents — qui permet le téléchargement de documents uniques ou en masse, l'archivage dans Apache Cassandra, l'analyse pilotée par l'IA, la transformation JSON, et le stockage dans PostgreSQL avec isolation des tenants. Utilisant des technologies comme Apache Kafka, Spark, LLaMA 3, Cassandra et PostgreSQL, le curriculum met l'accent sur des architectures prêtes pour la production avec des tests robustes, une surveillance et une optimisation. Avec 35 heures de formation hebdomadaire (7 heures/jour), des ressources structurées et un mentorat, les participants émergent comme des architectes experts prêts pour les défis d'entreprise.

\tableofcontents
\newpage

\section{Philosophie du Programme \& Objectifs}
% Définition de la philosophie de base du programme
Ce programme d'un mois transforme les professionnels du logiciel en architectes experts capables de concevoir des systèmes de microservices évolutifs, multi-tenants et pilotés par les événements intégrant la Conception Pilotée par les Événements (EDD), le Big Data, l'IA et la persistance polyglotte. Le curriculum repose sur trois piliers :
\begin{enumerate}
    \item \textbf{Maîtrise Technologique :} Compréhension profonde des outils comme Apache Kafka, Spark, LLaMA 3, Cassandra, PostgreSQL et les architectures multi-tenants.
    \item \textbf{Intégration Architecturale :} Combiner EDD, Big Data, IA, microservices et persistance polyglotte en systèmes cohérents et résilients.
    \item \textbf{Prêt pour la Production :} Prioriser les performances, la sécurité, l'isolation des tenants, les tests et la surveillance.
\end{enumerate}

% Description du projet capstone
\textbf{Projet Capstone :} Les participants concevront une \textbf{Plateforme Intelligente de Traitement de Documents}, un système basé sur des microservices permettant aux tenants de télécharger des documents (uniques ou en masse), d'archiver les métadonnées brutes dans Cassandra, d'analyser le contenu en utilisant LLaMA 3 pour l'extraction sémantique (par ex., numéros de factures), de transformer les données extraites en objets JSON, et de les stocker dans PostgreSQL avec isolation multi-tenants. Le système utilise Kafka pour l'orchestration pilotée par les événements, avec Cassandra pour l'archivage à haut volume et PostgreSQL pour le stockage structuré, soutenu par des tests complets, une surveillance et une optimisation.

% Ajout de contexte visuel
\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{capstone_architecture.pdf}
    \caption{Architecture de Microservices Pilotée par les Événements avec Persistance Polyglotte}
\end{figure}

% Transition à la section suivante
Cette philosophie guide la sélection du public cible et des prérequis, assurant que les participants sont équipés pour construire le système capstone.

\section{Public Cible \& Prérequis}

% Spécification des participants ciblés
\subsection{Public Cible}
\begin{itemize}
    \item Ingénieurs Logiciels Seniors passant à des rôles d'architecture
    \item Ingénieurs de Données assumant des responsabilités architecturales
    \item Ingénieurs DevOps construisant des infrastructures de données/IA évolutives
    \item Architectes de Solutions approfondissant leur expertise en systèmes multi-tenants
\end{itemize}

% Liste des compétences requises
\subsection{Prérequis Techniques}
\begin{itemize}
    \item Maîtrise de Java, Scala ou Python
    \item Compréhension solide des systèmes distribués (par ex., théorème CAP)
    \item Concepts avancés de SQL et NoSQL (par ex., indexation, espaces de clés)
    \item Familiarité avec Linux/Unix, Git et pipelines CI/CD
    \item Connaissances pratiques des plateformes cloud (AWS, Azure ou GCP)
    \item 3-5 ans d'expérience en développement logiciel
\end{itemize}

% Ajout de ressources pour la préparation
\subsection{Ressources Recommandées}
\begin{itemize}
    \item \textit{Livre :} \textit{Conception d'Applications Intensives en Données} par Martin Kleppmann
    \item \textit{Livre :} \textit{Construction de Microservices} par Sam Newman
    \item \textit{En ligne :} Fondamentaux de Kafka Confluent (\url{https://confluent.io/learn})
    \item \textit{En ligne :} Fondamentaux de Cassandra DataStax Academy (\url{https://www.datastax.com/learn})
    \item \textit{En ligne :} Guide des Microservices Microsoft Azure (\url{https://learn.microsoft.com/en-us/azure/architecture/microservices})
    \item \textit{En ligne :} Modélisation des Données dans Apache Cassandra (DataStax, \url{https://www.datastax.com/learn/cassandra-data-modeling})
    \item \textit{En ligne :} Guide JSONB PostgreSQL (\url{https://www.postgresql.org/docs/current/datatype-json.html})
\end{itemize}

% Transition
Ces prérequis préparent les participants aux technologies de base et aux laboratoires pratiques détaillés ensuite, construisant vers le projet capstone basé sur polyglot et microservices.

\section{Technologies \& Outils de Base}

% Détail des technologies EDD
\subsection{Pile de Conception Pilotée par les Événements}
\begin{itemize}
    \item \textbf{Apache Kafka :} Plateforme de base, Connect, Streams, Registre de Schémas
    \item \textbf{Debezium :} Capture de données de changement en temps réel
    \item \textbf{Avro/Protobuf :} Sérialisation pilotée par schémas
\end{itemize}

% Détail des technologies Big Data
\subsection{Cadre de Traitement de Big Data}
\begin{itemize}
    \item \textbf{Apache Spark :} Traitement de données à grande échelle avec Streaming Structuré
    \item \textbf{Delta Lake/Iceberg :} Formats de table conformes à ACID
    \item \textbf{Architecture Médaillon :} Couches Bronze, Argent, Or
\end{itemize}

% Détail des technologies IA/ML
\subsection{Écosystème d'Ingénierie IA/ML}
\begin{itemize}
    \item \textbf{MLflow :} Gestion du cycle de vie ML
    \item \textbf{Scikit-learn/TensorFlow/PyTorch :} Développement de modèles
    \item \textbf{Feast :} Stockage de fonctionnalités pour fonctionnalités multi-tenants
    \item \textbf{Serveur d'Inférence Triton :} Service de modèles
\end{itemize}

% Détail de l'orchestration et de l'infrastructure
\subsection{Orchestration \& Infrastructure}
\begin{itemize}
    \item \textbf{Kubernetes :} Orchestration de conteneurs
    \item \textbf{Docker :} Conteneurisation
    \item \textbf{FastAPI :} API RESTful pour le téléchargement de documents
    \item \textbf{Plateformes Cloud :} AWS (S3, EMR, EKS), Azure (ADLS, Databricks, AKS), GCP (GCS, Dataproc, GKE)
\end{itemize}

% Détail des composants spécifiques au capstone
\subsection{Composants de Pratique du Capstone}
\begin{itemize}
    \item \textbf{Apache Camel :} Routage de documents
    \item \textbf{Drools :} Règles métier pour validation JSON
    \item \textbf{Ollama/LLaMA 3 :} Analyse sémantique
    \item \textbf{PostgreSQL :} Stockage structuré avec JSONB
    \item \textbf{Apache Cassandra :} Stockage d'archivage à haut volume
    \item \textbf{Machine d'État Spring :} Gestion du cycle de vie des documents
    \item \textbf{Tesseract OCR :} Extraction de texte
    \item \textbf{Redis :} Cache distribué
    \item \textbf{Keycloak :} Authentification multi-tenants
    \item \textbf{Prometheus/Grafana :} Surveillance du système
    \item \textbf{JUnit/JMeter/K6 :} Cadres de tests
    \item \textbf{OpenLineage :} Suivi de lignée des données
\end{itemize}

% Transition
Ces technologies forment la base du plan de formation, permettant aux participants de construire un système basé sur microservices et polyglot pour le capstone.

\section{Plan de Formation Détaillé}

\subsection{Semaine 1 : Maîtrise Fondamentale \& Couche d'Ingestion}
\textbf{Objectifs :} Introduire les bases d'EDD, microservices et Big Data, construire la couche d'ingestion du capstone avec Kafka et Spark.

\subsubsection{Jour 1 : Fondations Kafka \& Pilotées par les Événements}
\textbf{Théorie (3h) :}
\begin{itemize}
    \item Introduction à l'EDD et Kafka (1h)
    \item Concepts de base : Topics, Partitions, Réplicas (1h)
    \item Meilleures pratiques pour la sécurité et la scalabilité (1h)
\end{itemize}
\textbf{Lab (3.5h) :} Configurer Kafka avec Docker
\begin{itemize}
    \item \textit{Objectif :} Installer et configurer un cluster Kafka local pour la couche d'ingestion.
    \item \textit{Étapes :}
        \begin{enumerate}
            \item Installer Docker Desktop et vérifier les prérequis.
            \item Créer un fichier \texttt{docker-compose.yml} pour Kafka, Zookeeper et Kafdrop.
            \item Lancer le cluster avec \texttt{docker-compose up -d}.
            \item Vérifier via Kafdrop (\texttt{http://localhost:9000}).
            \item Compléter le Vérification des Connaissances sur Kafka.
        \end{enumerate}
    \item \textit{Technologies :} Docker, Kafka, Kafdrop
    \item \textit{Support :} Templates \texttt{docker-compose.yml}, guide d'installation.
\end{itemize}
\textbf{Clôture (0.5h) :}
\begin{itemize}
    \item Révision de la configuration Kafka.
    \item \textit{Progression Capstone :} Couche d'ingestion Kafka initiale.
\end{itemize}

\subsubsection{Jour 2 : Microservices \& Téléchargements en Masse}
\textbf{Théorie (3h) :}
\begin{itemize}
    \item Principes des microservices (1h)
    \item Conception d'API RESTful avec FastAPI (1h)
    \item Gestion des téléchargements en masse (1h)
\end{itemize}
\textbf{Lab (3.5h) :} Développer un microservice de téléchargement
\begin{itemize}
    \item \textit{Objectif :} Créer un microservice pour gérer les téléchargements de documents.
    \item \textit{Étapes :}
        \begin{enumerate}
            \item Configurer un projet FastAPI avec Docker.
            \item Implémenter une API pour les téléchargements uniques et en masse.
            \item Intégrer avec Kafka pour publier des événements \texttt{DocumentUploaded}.
            \item Tester avec cURL ou Postman.
            \item Compléter le Vérification des Connaissances sur les microservices.
        \end{enumerate}
    \item \textit{Technologies :} FastAPI, Docker, Kafka
    \item \textit{Support :} Code de démarrage FastAPI, guide d'intégration Kafka.
\end{itemize}
\textbf{Clôture (0.5h) :}
\begin{itemize}
    \item Discussion sur les défis d'API.
    \item \textit{Progression Capstone :} Microservice de téléchargement fonctionnel.
\end{itemize}

\subsubsection{Jour 3 : Streaming Spark \& Delta Lake}
\textbf{Théorie (3h) :}
\begin{itemize}
    \item Introduction à Spark Streaming (1h)
    \item Architecture Médaillon et Delta Lake (1h)
    \item Traitement des données en temps réel (1h)
\end{itemize}
\textbf{Lab (3.5h) :} Configurer le streaming Spark
\begin{itemize}
    \item \textit{Objectif :} Mettre en place un pipeline Spark pour traiter les événements Kafka.
    \item \textit{Étapes :}
        \begin{enumerate}
            \item Installer Spark avec Docker.
            \item Configurer un travail Spark pour consommer des événements Kafka.
            \item Stocker les données dans Delta Lake (couche Bronze).
            \item Vérifier avec Spark UI.
            \item Compléter le Vérification des Connaissances sur Spark.
        \end{enumerate}
    \item \textit{Technologies :} Spark, Delta Lake, Kafka
    \item \textit{Support :} Configuration Spark, exemples de code.
\end{itemize}
\textbf{Clôture (0.5h) :}
\begin{itemize}
    \item Révision du pipeline Spark.
    \item \textit{Progression Capstone :} Pipeline de streaming initial.
\end{itemize}

\subsubsection{Jour 4 : MLOps \& Cycle de Vie des Modèles}
\textbf{Théorie (3h) :}
\begin{itemize}
    \item Introduction à MLOps (1h)
    \item Gestion du cycle de vie avec MLflow (1h)
    \item Intégration de modèles IA (1h)
\end{itemize}
\textbf{Lab (3.5h) :} Déployer un modèle LLaMA 3
\begin{itemize}
    \item \textit{Objectif :} Intégrer un modèle d'analyse sémantique dans le pipeline.
    \item \textit{Étapes :}
        \begin{enumerate}
            \item Installer MLflow et LLaMA 3 via Docker.
            \item Entraîner un modèle simple pour extraire des métadonnées.
            \item Déployer avec Triton Inference Server.
            \item Intégrer avec Spark pour le traitement.
            \item Compléter le Vérification des Connaissances sur MLOps.
        \end{enumerate}
    \item \textit{Technologies :} MLflow, LLaMA 3, Triton, Spark
    \item \textit{Support :} Scripts d'entraînement, guide d'intégration.
\end{itemize}
\textbf{Clôture (0.5h) :}
\begin{itemize}
    \item Discussion sur les défis d'IA.
    \item \textit{Progression Capstone :} Analyse sémantique intégrée.
\end{itemize}

\subsubsection{Jour 5 : Pipeline d'Ingestion Capstone}
\textbf{Théorie (3h) :}
\begin{itemize}
    \item Revue des couches d'ingestion (1h)
    \item Optimisation de la performance (1h)
    \item Surveillance avec Prometheus (1h)
\end{itemize}
\textbf{Lab (3.5h) :} Intégrer la couche d'ingestion
\begin{itemize}
    \item \textit{Objectif :} Combiner les composants en un pipeline d'ingestion.
    \item \textit{Étapes :}
        \begin{enumerate}
            \item Connecter le microservice, Spark et le modèle IA.
            \item Configurer Prometheus pour la surveillance.
            \item Tester le pipeline avec des données simulées.
            \item Documenter les résultats.
            \item Compléter le Vérification des Connaissances sur l'ingestion.
        \end{enumerate}
    \item \textit{Technologies :} Kafka, Spark, FastAPI, Prometheus
    \item \textit{Support :} Templates de configuration, jeux de données.
\end{itemize}
\textbf{Clôture (0.5h) :}
\begin{itemize}
    \item Revue du pipeline.
    \item \textit{Progression Capstone :} Couche d'ingestion complète.
\end{itemize}

\textbf{Revue de la Semaine :}
\begin{itemize}
    \item \textit{Délivrables :} Configuration Kafka, microservice de téléchargement, pipeline Spark, modèle IA intégré.
    \item \textit{Étape Importante :} Soumettre la revue de la couche d'ingestion.
\end{itemize}

\subsection{Semaine 2 : Intégration Architecturale}
\textbf{Objectifs :} Intégrer la persistance polyglotte, l'isolation des tenants et l'orchestration.

\subsubsection{Jour 1 : Bases de Cassandra \& Modélisation}
\textbf{Théorie (3h) :}
\begin{itemize}
    \item Introduction à Cassandra (1h)
    \item Modélisation des données (1h)
    \item Meilleures pratiques pour l'archivage (1h)
\end{itemize}
\textbf{Lab (3.5h) :} Configurer Cassandra
\begin{itemize}
    \item \textit{Objectif :} Mettre en place un cluster Cassandra pour l'archivage.
    \item \textit{Étapes :}
        \begin{enumerate}
            \item Installer Cassandra avec Docker.
            \item Créer un schéma pour les métadonnées brutes.
            \item Intégrer avec Spark pour l'écriture.
            \item Vérifier les performances.
            \item Compléter le Vérification des Connaissances sur Cassandra.
        \end{enumerate}
    \item \textit{Technologies :} Cassandra, Spark
    \item \textit{Support :} Schémas de base de données, guide d'installation.
\end{itemize}
\textbf{Clôture (0.5h) :}
\begin{itemize}
    \item Discussion sur les défis de modélisation.
    \item \textit{Progression Capstone :} Archivage Cassandra initial.
\end{itemize}

\subsubsection{Jour 2 : PostgreSQL \& JSONB}
\textbf{Théorie (3h) :}
\begin{itemize}
    \item Introduction à PostgreSQL (1h)
    \item Utilisation de JSONB (1h)
    \item Isolation des tenants (1h)
\end{itemize}
\textbf{Lab (3.5h) :} Configurer PostgreSQL
\begin{itemize}
    \item \textit{Objectif :} Mettre en place une base PostgreSQL pour le stockage structuré.
    \item \textit{Étapes :}
        \begin{enumerate}
            \item Installer PostgreSQL avec Docker.
            \item Créer des tables avec isolation par tenant.
            \item Intégrer avec le modèle IA pour les données JSON.
            \item Tester les requêtes.
            \item Compléter le Vérification des Connaissances sur PostgreSQL.
        \end{enumerate}
    \item \textit{Technologies :} PostgreSQL, LLaMA 3
    \item \textit{Support :} Schémas SQL, exemples JSON.
\end{itemize}
\textbf{Clôture (0.5h) :}
\begin{itemize}
    \item Revue des défis d'isolation.
    \item \textit{Progression Capstone :} Stockage PostgreSQL initial.
\end{itemize}

\subsubsection{Jour 3 : Orchestration avec Kubernetes}
\textbf{Théorie (3h) :}
\begin{itemize}
    \item Introduction à Kubernetes (1h)
    \item Déploiement de microservices (1h)
    \item Gestion des ressources (1h)
\end{itemize}
\textbf{Lab (3.5h) :} Déployer sur Kubernetes
\begin{itemize}
    \item \textit{Objectif :} Déployer les microservices sur Kubernetes.
    \item \textit{Étapes :}
        \begin{enumerate}
            \item Configurer un cluster Kubernetes local.
            \item Déployer les microservices Kafka, Spark et IA.
            \item Configurer l'équilibrage de charge.
            \item Vérifier avec kubectl.
            \item Compléter le Vérification des Connaissances sur Kubernetes.
        \end{enumerate}
    \item \textit{Technologies :} Kubernetes, Docker
    \item \textit{Support :} Fichiers YAML, guide de déploiement.
\end{itemize}
\textbf{Clôture (0.5h) :}
\begin{itemize}
    \item Discussion sur l'orchestration.
    \item \textit{Progression Capstone :} Déploiement Kubernetes initial.
\end{itemize}

\subsubsection{Jour 4 : Sécurité \& Multi-Tenancy}
\textbf{Théorie (3h) :}
\begin{itemize}
    \item Sécurité des microservices (1h)
    \item Stratégies multi-tenants (1h)
    \item Authentification avec Keycloak (1h)
\end{itemize}
\textbf{Lab (3.5h) :} Sécuriser le système
\begin{itemize}
    \item \textit{Objectif :} Implémenter la sécurité et l'isolation des tenants.
    \item \textit{Étapes :}
        \begin{enumerate}
            \item Configurer Keycloak pour l'authentification.
            \item Appliquer des politiques d'isolation dans Cassandra et PostgreSQL.
            \item Tester l'accès tenant-spécifique.
            \item Vérifier avec des logs.
            \item Compléter le Vérification des Connaissances sur la sécurité.
        \end{enumerate}
    \item \textit{Technologies :} Keycloak, Cassandra, PostgreSQL
    \item \textit{Support :} Configurations de sécurité, guides.
\end{itemize}
\textbf{Clôture (0.5h) :}
\begin{itemize}
    \item Revue de la sécurité.
    \item \textit{Progression Capstone :} Sécurité et multi-tenancy initiales.
\end{itemize}

\subsubsection{Jour 5 : Intégration des Couches}
\textbf{Théorie (3h) :}
\begin{itemize}
    \item Revue de l'architecture (1h)
    \item Optimisation des performances (1h)
    \item Surveillance globale (1h)
\end{itemize}
\textbf{Lab (3.5h) :} Intégrer les couches
\begin{itemize}
    \item \textit{Objectif :} Combiner ingestion, persistance et orchestration.
    \item \textit{Étapes :}
        \begin{enumerate}
            \item Connecter Kafka, Spark, Cassandra et PostgreSQL.
            \item Optimiser les performances avec des index.
            \item Configurer Prometheus/Grafana pour la surveillance.
            \item Tester l'ensemble.
            \item Compléter le Vérification des Connaissances sur l'intégration.
        \end{enumerate}
    \item \textit{Technologies :} Kafka, Spark, Cassandra, PostgreSQL, Prometheus
    \item \textit{Support :} Scripts d'intégration, tableaux de bord.
\end{itemize}
\textbf{Clôture (0.5h) :}
\begin{itemize}
    \item Revue de l'intégration.
    \item \textit{Progression Capstone :} Système intégré partiel.
\end{itemize}

\textbf{Revue de la Semaine :}
\begin{itemize}
    \item \textit{Délivrables :} Configuration Cassandra, PostgreSQL, déploiement Kubernetes, sécurité initiale.
    \item \textit{Étape Importante :} Soumettre la revue de l'intégration architecturale.
\end{itemize}

\subsection{Semaine 3 : Prêt pour la Production}
\textbf{Objectifs :} Optimiser, tester et surveiller le système.

\subsubsection{Jour 1 : Tests de Charge}
\textbf{Théorie (3h) :}
\begin{itemize}
    \item Introduction aux tests de charge (1h)
    \item Utilisation de JMeter/K6 (1h)
    \item Définition des SLA (1h)
\end{itemize}
\textbf{Lab (3.5h) :} Tester la charge
\begin{itemize}
    \item \textit{Objectif :} Évaluer les performances sous charge.
    \item \textit{Étapes :}
        \begin{enumerate}
            \item Configurer JMeter/K6 pour simuler des téléchargements.
            \item Tester les microservices et bases de données.
            \item Analyser les résultats.
            \item Ajuster les configurations.
            \item Compléter le Vérification des Connaissances sur les tests.
        \end{enumerate}
    \item \textit{Technologies :} JMeter, K6
    \item \textit{Support :} Scripts de test, guides.
\end{itemize}
\textbf{Clôture (0.5h) :}
\begin{itemize}
    \item Discussion sur les résultats.
    \item \textit{Progression Capstone :} Tests de charge initiaux.
\end{itemize}

\subsubsection{Jour 2 : Surveillance \& Logging}
\textbf{Théorie (3h) :}
\begin{itemize}
    \item Surveillance avec Prometheus/Grafana (1h)
    \item Journalisation structurée (1h)
    \item Débogage des flux asynchrones (1h)
\end{itemize}
\textbf{Lab (3.5h) :} Configurer la surveillance
\begin{itemize}
    \item \textit{Objectif :} Mettre en place une surveillance complète.
    \item \textit{Étapes :}
        \begin{enumerate}
            \item Configurer Prometheus pour les métriques.
            \item Créer des tableaux de bord Grafana.
            \item Implémenter la journalisation avec ELK.
            \item Tester les alertes.
            \item Compléter le Vérification des Connaissances sur la surveillance.
        \end{enumerate}
    \item \textit{Technologies :} Prometheus, Grafana, ELK
    \item \textit{Support :} Templates de tableau de bord, guides.
\end{itemize}
\textbf{Clôture (0.5h) :}
\begin{itemize}
    \item Revue de la surveillance.
    \item \textit{Progression Capstone :} Surveillance initiale.
\end{itemize}

\subsubsection{Jour 3 : Sécurité Renforcée}
\textbf{Théorie (3h) :}
\begin{itemize}
    \item Renforcement de la sécurité pour les microservices polyglottes (1h)
    \item Vérifications de conformité GDPR pour Cassandra/PostgreSQL (1h)
    \item Surveillance des métriques de sécurité (1h)
\end{itemize}
\textbf{Lab (3.5h) :} Renforcer la sécurité polyglotte
\begin{itemize}
    \item \textit{Objectif :} Sécuriser Cassandra et PostgreSQL avec surveillance dans les microservices.
    \item \textit{Étapes :}
        \begin{enumerate}
            \item Chiffrer les données JSON dans PostgreSQL et Cassandra.
            \item Renforcer Kubernetes avec des politiques de sécurité des pods.
            \item Effectuer des vérifications de conformité GDPR.
            \item Rédiger des tests de sécurité pour l'isolation des tenants.
            \item Surveiller les métriques de sécurité avec Prometheus.
            \item Compléter le Vérification des Connaissances sur les tests de sécurité.
        \end{enumerate}
    \item \textit{Technologies :} Kubernetes, Keycloak, PostgreSQL, Cassandra, Prometheus
    \item \textit{Support :} Politiques de sécurité préconfigurées, templates de chiffrement.
\end{itemize}
\textbf{Clôture (0.5h) :}
\begin{itemize}
    \item Revue des mesures de sécurité.
    \item \textit{Progression Capstone :} Sécurité renforcée du système polyglotte.
\end{itemize}

\subsubsection{Jour 4 : Documentation \& Manuels}
\textbf{Théorie (3h) :}
\begin{itemize}
    \item Documentation de l'architecture pour les microservices et la persistance polyglotte (1h)
    \item Création de manuels multi-tenants (1h)
    \item Documentation des configurations de test/surveillance (1h)
\end{itemize}
\textbf{Lab (3.5h) :} Documenter le système polyglotte
\begin{itemize}
    \item \textit{Objectif :} Produire une documentation pour le système basé sur les microservices avec persistance polyglotte.
    \item \textit{Étapes :}
        \begin{enumerate}
            \item Créer des diagrammes d'architecture avec draw.io pour les microservices et Cassandra/PostgreSQL.
            \item Rédiger des manuels pour les opérations spécifiques aux tenants.
            \item Documenter les cas de test et la surveillance pour Cassandra/PostgreSQL.
            \item Réviser avec les pairs ; valider avec le Vérification des Connaissances.
        \end{enumerate}
    \item \textit{Technologies :} draw.io, LaTeX, Markdown
    \item \textit{Support :} Templates de diagrammes, échantillons de manuels.
\end{itemize}
\textbf{Clôture (0.5h) :}
\begin{itemize}
    \item Discussion sur la qualité de la documentation.
    \item \textit{Progression Capstone :} Système polyglotte documenté.
\end{itemize}

\subsubsection{Jour 5 : Présentation Finale}
\textbf{Théorie (3h) :}
\begin{itemize}
    \item Compétences de présentation pour architectes (1h)
    \item Défense des décisions de conception (1h)
    \item Présentation des résultats de test et de surveillance (1h)
\end{itemize}
\textbf{Lab (3.5h) :} Présenter le système polyglotte
\begin{itemize}
    \item \textit{Objectif :} Délivrer une démo du système de traitement de documents basé sur les microservices.
    \item \textit{Étapes :}
        \begin{enumerate}
            \item Préparer une démo en direct du téléchargement, de l'IA, de l'archivage Cassandra et du stockage PostgreSQL.
            \item Créer des diapositives mettant en évidence l'architecture, la persistance polyglotte, les tests et la surveillance.
            \item S'entraîner avec Q\&A.
            \item Présenter aux pairs/instructeurs.
            \item Compléter le Vérification des Connaissances sur la clarté de la présentation.
        \end{enumerate}
    \item \textit{Technologies :} PowerPoint, Kubernetes, FastAPI, Cassandra, PostgreSQL
    \item \textit{Support :} Template de présentation.
\end{itemize}
\textbf{Clôture (0.5h) :}
\begin{itemize}
    \item Finaliser les livrables.
    \item \textit{Progression Capstone :} Système polyglotte complet présenté.
\end{itemize}

\textbf{Revue de la Semaine :}
\begin{itemize}
    \item \textit{Délivrables :} Système polyglotte prêt pour la production avec tests de charge, surveillance, sécurité renforcée, documentation, présentation.
    \item \textit{Étape Importante :} Soumettre les livrables finaux du capstone.
\end{itemize}

\section{Métriques de Succès \& Évaluation}

\subsection{Cadre d'Évaluation}
\begin{itemize}
    \item \textbf{Complétion Hebdomadaire des Labs (30\%) :} Qualité des implémentations, tests et surveillance, évaluée via les revues des mentors et les Vérifications des Connaissances.
    \item \textbf{Projet Capstone (50\%) :}
        \begin{itemize}
            \item \textit{Fonctionnalité (15\%) :} Traitement fiable des documents polyglottes avec microservices.
            \item \textit{Qualité Architecturale (15\%) :} Évolutivité, maintenabilité, isolation des tenants dans les microservices et bases de données polyglottes.
            \item \textit{Qualité du Code (10\%) :} Code propre, couverture de tests.
            \item \textit{Performance (10\%) :} Respect des SLA multi-tenants avec optimisation.
        \end{itemize}
    \item \textbf{Présentation Finale (20\%) :} Clarté dans l'articulation de l'architecture, la persistance polyglotte, les tests et la surveillance.
\end{itemize}

\subsection{Critères d'Évaluation (Alignés avec les Piliers du Programme)}
\begin{itemize}
    \item \textbf{Maîtrise Technologique :} Profondeur dans EDD, Big Data, IA, microservices, persistance polyglotte, tests et surveillance.
    \item \textbf{Intégration Architecturale :} Conception de systèmes cohérents multi-tenants avec Cassandra et PostgreSQL.
    \item \textbf{Prêt pour la Production :} Focus sur performance, sécurité, scalabilité, tests et surveillance.
    \item \textbf{Résolution de Problèmes :} Innovation dans les défis polyglottes et microservices.
    \item \textbf{Communication :} Collaboration efficace et présentation des résultats.
\end{itemize}

\section{Méthodologie d'Enseignement}

\subsection{Approche d'Apprentissage}
\begin{itemize}
    \item \textbf{Sessions Théoriques (43\%) :} Ateliers sur les concepts, microservices, persistance polyglotte, tests et surveillance.
    \item \textbf{Labs Pratiques (50\%) :} Scénarios pratiques multi-tenants avec microservices et stockage polyglotte.
    \item \textbf{Clôtures (7\%) :} Réflexion quotidienne et Q\&A.
    \item \textbf{Mentorat :} Sessions individuelles hebdomadaires avec des architectes.
    \item \textbf{Apprentissage Collaboratif :} Programmation en binôme, revues de groupe.
\end{itemize}

\subsection{Modèle de Livraison}
\begin{itemize}
    \item Ateliers dirigés par des experts par Sami Mbarki et son équipe
    \item Labs guidés avec revues d'architecture microservice, polyglotte, test et surveillance
    \item Apprentissage entre pairs via résolution collaborative de problèmes
    \item Retours continus et amélioration itérative
    \item Environnement semblable à la production avec des outils d'entreprise
\end{itemize}

\subsection{Soutien pour Apprenants Divers}
\begin{itemize}
    \item \textbf{Rafraîchisseurs Pré-Cours :} Modules optionnels sur Kafka, Spark, Cassandra, PostgreSQL et microservices.
    \item \textbf{Pistes Avancées :} Plongées approfondies dans l'optimisation microservice, polyglotte et surveillance.
    \item \textbf{Vérifications des Connaissances :} Quizzes quotidiens sur microservices, polyglotte et tests.
    \item \textbf{Revues d'Étape :} Réflexions sur les progrès du capstone hebdomadaires.
\end{itemize}

\section{Terminologie}
\begin{itemize}
    \item \textbf{Multi-Tenancy :} Conception de systèmes pour isoler et traiter sécuritairement les données de multiples clients (tenants) dans une infrastructure partagée.
    \item \textbf{Conception Pilotée par les Événements (EDD) :} Architecture utilisant des événements pour déclencher et communiquer entre services découplés.
    \item \textbf{Microservices :} Services petits, déployables indépendamment, gérant des fonctions métier spécifiques, communiquant via API ou événements.
    \item \textbf{Persistance Polyglotte :} Utilisation de multiples bases de données (par ex., Cassandra, PostgreSQL) pour optimiser les besoins de données différents.
\end{itemize}

\end{document}