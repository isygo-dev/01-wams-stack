\documentclass[11pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{helvet}
\usepackage{booktabs, tabularx, multirow}
\usepackage{enumitem}
\usepackage{hyperref}
\usepackage{fancyhdr}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{minted}
\usepackage{titling}
\usepackage[bottom]{footmisc}
\usepackage{titlesec}
\usepackage{parskip}
\usepackage{amsmath}
\usepackage{listings}

\definecolor{primaryblue}{RGB}{0, 102, 204}
\definecolor{secondarygray}{RGB}{80, 80, 80}
\definecolor{codebg}{RGB}{245, 245, 245}

\hypersetup{
    colorlinks=true,
    linkcolor=primaryblue,
    filecolor=magenta,
    urlcolor=cyan,
    pdftitle={1-Month Expert Architecture Training Plan: Week 1, Day 3},
    bookmarks=true,
}

\pagestyle{fancy}
\fancyhf{}
\rhead{\textbf{1-Month Expert Architecture Training}}
\lhead{\textbf{ISYGO Consulting Services}}
\rfoot{Page \thepage}

\titleformat{\section}{\Large\bfseries\sffamily\color{primaryblue}}{\thesection}{1em}{}
\titleformat{\subsection}{\large\bfseries\sffamily\color{secondarygray}}{\thesubsection}{1em}{}
\titleformat{\subsubsection}{\normalsize\bfseries\sffamily\color{secondarygray}}{\thesubsubsection}{1em}{}

\setlist[itemize]{noitemsep,topsep=2pt}
\setlist[enumerate]{noitemsep,topsep=2pt}

\lstset{
  backgroundcolor=\color{codebg},
  basicstyle=\small\ttfamily,
  frame=single,
  breaklines=true,
}

\begin{document}

\begin{titlepage}
    \centering
    \vspace*{1cm}
    \vspace{0.5cm}
    {\color{primaryblue}\hrule height 2pt}
    \vspace{0.5cm}
    {\LARGE\sffamily\bfseries 1-Month Expert Architecture Training Plan\par}
    \vspace{0.3cm}
    {\large\sffamily\itshape Week 1, Day 3: Real-Time Ingestion and Reliable Storage\par}
    \vspace{1.5cm}
    {\large\sffamily Prepared by: Sami Mbarki \\ Solution Architect, Java Expert \\ ISYGO Consulting Services}
    \vspace{1cm}
    {\large\sffamily 18 September 2025}
    \vfill
    \begin{minipage}{0.8\textwidth}
        \centering
        \small\sffamily \textbf{ISYGO Consulting Services} \\
        \small\sffamily Delivering Advanced Architectural Training for Enterprise Solutions \\
        \vspace{0.5cm}
        \small\sffamily Document ID: d3d09d59-7b6d-4ba2-b4de-7cbc28a8b12b \\
        \small\sffamily Version: 1.0 \\
        \small\sffamily Confidential: For Internal Training Use Only
    \end{minipage}
    {\color{primaryblue}\hrule height 2pt}
\end{titlepage}

\pretitle{\begin{center}\LARGE\sffamily\bfseries}
\posttitle{\end{center}}
\preauthor{\begin{center}\large\sffamily}
\postauthor{\end{center}}
\predate{\begin{center}\large\sffamily}
\postdate{\end{center}}

\pagestyle{fancy}
\title{1-Month Expert Training in Microservices and Polyglot Persistence}
\author{Sami Mbarki \\ Solution Architect, Java Expert \\ ISYGO Consulting Services}
\date{18 September 2025}
\maketitle

\tableofcontents
\newpage

\section{Preface: Streaming and Storage in Big Data}
This detailed chapter turns Day 3 into a student textbook, with definitions (e.g., "stream processing"), terminologies (e.g., "micro-batch"), clarifications on concepts like watermarking, technologies (Spark, Delta Lake), and alternatives (Flink, Iceberg). Include exercises to apply ideas.

\subsection{How to Use This Book}
- Use equations for performance calculations.
- Explore alternatives for informed choices.

\section{Introduction: Processing Data in Motion}
Why process data in real-time rather than batches? Structured Streaming in Spark enables continuous applications. Historical: Spark started as batch (2010), evolved to streaming with DStreams (2013), then Structured (2016). Alternatives: Apache Flink for true continuous processing.

\subsection{Learning Objectives}
Including sub-objectives like calculating watermark thresholds.

\section{Core Theory: Structured Streaming}
\subsection{Evolution from DStreams}
Definition: DStreams are discretized streams of RDDs. Clarification: Structured Streaming uses DataFrames for unified batch/streaming.

\subsection{Micro-Batch Execution Model}
Definition: Processes data in small batches at triggers.

Terminology: "Unbounded table" - logical view of growing data.

Clarification: Trigger types - processing time, once.

Equation: Batch size ≈ trigger interval * ingress rate.

Alternatives: Flink's windowing for lower latency.

Pitfalls: Long micro-batches increase latency; tune triggers.

Code Example:
\begin{minted}[frame=single,fontsize=\small,bgcolor=codebg]{python}
query = df.writeStream \
    .format("console") \
    .trigger(processingTime='5 seconds') \
    .start()
\end{minted}

\subsection{Watermarking for Late Data}
Definition: Watermark is a threshold for late events, based on event time.

Terminology: "Event time" vs "processing time".

Clarification: Watermark = max_event_time - delay_threshold.

Equation: Drop if event_time < watermark.

Example: .withWatermark("timestamp", "10 minutes")

Advanced: Handling multiple watermarks in joins.

Pitfalls: Too aggressive watermark drops valid data.

\section{The Medallion Architecture}
Definition: Layered data refinement - Bronze (raw, Parquet), Silver (cleansed, validated), Gold (aggregated, business-ready).

Terminology: "Data lakehouse" - lake storage with warehouse features.

Clarification: Bronze for ingestion, Silver for cleaning (e.g., dedup), Gold for analytics.

Alternatives: Use Apache Iceberg for schema evolution over Delta Lake.

Diagram:
\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{medallion_architecture.pdf}
    \caption{Layers with Data Flow and Transformations}
\end{figure}

Best Practices: Use Delta Lake for ACID in lakehouse.

Case Study: Databricks' use in healthcare for compliant data.

\section{Delta Lake: Reliable Storage Layer}
Definition: Open-source storage adding transaction log to Parquet.

Terminology: "ACID" - Atomicity, Consistency, Isolation, Durability.

Clarification: Time travel via versions; schema enforcement prevents bad data.

Features:
- Transactions: Concurrent writes.
- Upserts: MERGE INTO.
- Deletion: VACUUM for GDPR.

Alternatives: Apache Hudi for upsert-heavy workloads, Iceberg for multi-engine support.

Code:
\begin{minted}[frame=single,fontsize=\small,bgcolor=codebg]{sql}
MERGE INTO delta.`/delta/docs` AS target
USING updates
ON target.id = updates.id
WHEN MATCHED THEN UPDATE SET *
WHEN NOT MATCHED THEN INSERT *
\end{minted}

Pitfalls: Ignoring optimization (Z-Ordering) leads to slow queries.

\section{Spark Optimization Techniques}
\subsection{Data Partitioning}
Definition: Divides data into directories by column values.

Terminology: "Partition pruning" - skips irrelevant partitions.

Clarification: Predicate pushdown optimizes filters.

Equation: Query time ∝ data scanned; pruning reduces by factor of partitions.

Code: .partitionBy("tenant_id")

Alternatives: Bucketing for joins.

\subsection{Caching and Persistence}
Definition: Caches DataFrames in memory/disk.

Terminology: "Persistence levels" - MEMORY_ONLY, DISK_ONLY.

Clarification: Use .cache() for repeated access.

Pitfalls: Caching large data causes OOM; use .persist(StorageLevel.MEMORY_AND_DISK).

Advanced: Checkpointing for fault recovery in streaming.

\section{Lab: Building a Real-Time Pipeline}
Detailed with basic/advanced tracks, code templates, troubleshooting.

\section{Wrap-Up: Socratic Discussion}
Discuss: How does Delta Lake solve data lake problems? What alternative to Spark for streaming?

\section{Student Exercises and Review Questions}
1. Implement a watermark in code.
2. Compare Delta Lake and Iceberg.

\section{Glossary}
Expanded:
\begin{itemize}
    \item \textbf{Micro-Batch}: Discrete processing interval.
    \item \textbf{Watermark}: Late data threshold.
    \item \textbf{ACID Transactions}: Reliability guarantees.
    \item \textbf{Predicate Pushdown}: Filter optimization.
    \item \textbf{Z-Ordering}: Multi-dimensional clustering.
\end{itemize}

\section{References and Further Reading}
Books:
\begin{itemize}
    \item Zaharia, Matei, et al. \textit{Learning Spark}. O'Reilly, 2020.
    \item Armbrust, Michael, et al. \textit{Delta Lake: High-Performance ACID Table Storage over Cloud Object Stores}. VLDB 2020.
\end{itemize}

Online:
\begin{itemize}
    \item Spark Docs: \url{https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html}.
    \item Delta Lake: \url{https://delta.io}.
\end{itemize}

\end{document}