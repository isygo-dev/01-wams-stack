server:
  port: 8081
  compression:
    enabled: true
    mime-types: application/json
    min-response-size: 1024

spring:
  application:
    name: Poc AI Integration

  jackson:
    serialization:
      indent-output: true
    default-property-inclusion: non_null

  kafka:
    producer:
      bootstrap-servers: host.docker.internal:9092  # Replace with host IP (e.g., 192.168.1.100:9092) on Linux
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.ByteArraySerializer
    consumer:
      bootstrap-servers: host.docker.internal:9092  # Replace with host IP (e.g., 192.168.1.100:9092) on Linux
      group-id: my-consumer-group
      auto-offset-reset: earliest
      enable-auto-commit: false
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.ByteArrayDeserializer
      properties:
        enable.metrics.push: false
        session.timeout.ms: 60000
        heartbeat.interval.ms: 3000
        max.poll.interval.ms: 300000
    retry:
      enabled: true

management:
  endpoints:
    web:
      exposure:
        include: prometheus

kafka:
  topic:
    string-topic: string-topic
    file-topic: file-topic
  schemas:
    # Replace with absolute paths to actual schema files
    email-schema: file:/absolute/path/to/email-schema.json
    xml-message-xsd: file:/absolute/path/to/xml-message.xsd
  security:
    enable-hmac: false
    hmac-secret: ""
    enable-encryption: false
    aes-key: ""
    enable-json-validation: false
    enable-xml-validation: false

logging:
  level:
    root: INFO
    eu.isygoit.openai: DEBUG
    org.apache.kafka: DEBUG
  file:
    name: logs/application.log
  pattern:
    file: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"